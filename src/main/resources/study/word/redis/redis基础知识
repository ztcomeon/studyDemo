
敖丙：
============================
java面试之redis基础.pdf

1.看你简历上写了你项⽬⾥⾯⽤到了Redis，你们为啥⽤Redis？
高并发--mysql局限--缓存
关系型数据库如Mysql已经不能适⽤所有的场景了，秒杀的库存扣减， APP首页的访问流量⾼峰等等都很容易把数据库打崩，
所以引⼊了缓存中间件，缓存中间件有Redis 和 Memcached，最后选择了Redis。

2.Redis有哪些数据结构
字符串String、字典Hash、列表List、集合Set、有序集合SortedSet
高级的数据结构 HyperLogLog、 Geo、 Pub/Sub
还想加分 Redis Module，像BloomFilter， RedisSearch， Redis-ML，

3.如果有⼤量的key需要设置同⼀时间过期，⼀般需要注意什么？
redis可能会出现短暂的卡顿现象，严重的话会出现缓存雪崩，我们⼀般需要在时间上加⼀个随机值
电商⾸页经常会使⽤定时任务刷新缓存

4.那你使⽤过Redis分布式锁么，它是什么回事？
先拿setnx来争抢锁，抢到之后，再⽤expire给锁加⼀个过期时间防⽌锁忘记了释放

5.如果在setnx之后执⾏expire之前进程意外crash或者要重启维护了，那会怎么样？
set指令有⾮常复杂的参数，这个应该是可以同时把把setnx和expire合成⼀条指令来⽤的
Redis的分布式锁可以查看 html的教程

6.假如Redis⾥⾯有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？
使⽤keys指令可以扫出指定模式的key列表

7.如果这个redis正在给线上的业务提供服务，那使⽤keys指令会有什么问题？
redis的单线程的。 keys指令会导致线程阻塞⼀段时间，线上服务会停顿，直到指令执⾏完毕，服务才能恢复
这个时候可以使⽤scan指令， scan指令可以⽆阻塞的提取出指定模式的key列表，但是会有⼀定的重复概率
在客户端做⼀次去重就可以了，但是整体所花费的时间会⽐直接⽤keys指令长（本质是分段去keys）
增量式迭代命令也不是没有缺点的：因为在对键进⾏增量式迭代的过程中， 键可能会被修改， 所以增量式迭代命令
只能对被返回的元素提供有限的保证

8.使⽤过Redis做异步队列么，你是怎么⽤的？
⼀般使⽤list结构作为队列， rpush⽣产消息， lpop消费消息。当lpop没有消息的时候，要适当sleep⼀
会再重试

9.对⽅追问可不可以不⽤sleep呢？
list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来

10.对⽅接着追问能不能⽣产⼀次消费多次呢？
使⽤pub/sub主题订阅者模式，可以实现 1:N 的消息队列。

11.如果对⽅继续追问 pub/su b有什么缺点？
在消费者下线的情况下，⽣产的消息会丢失，得使⽤专业的消息队列如RocketMQ等。

12.如果对⽅究极TM追问Redis如何实现延时队列？
sortedset，拿时间戳作为score，消息内容作为key调⽤zadd来⽣产消息，消费者
⽤zrangebyscore指令获取N秒之前的数据轮询进⾏处理

13.Redis是怎么持久化的？服务主从数据怎么交互的？
RDB做镜像全量持久化， AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致⼤量丢失数据，
所以需要AOF来配合使⽤。在redis实例重启时，会使⽤RDB持久化⽂件重新构建内存，再使⽤AOF重放近期的操作指
令来实现完整恢复重启之前的状态。
RDB理解为⼀整个表全量的数据， AOF理解为每次操作的⽇志就好了，服务器重启的时候先把表的数据全部搞进去，
但是他可能不完整，你再回放⼀下⽇志，数据不就完整了，但是：Redis本身的机制是 AOF持久化开启且存在AOF⽂件时，
优先加载AOF⽂件；AOF关闭或者AOF⽂件不存在时，加载RDB⽂件；加载AOF/RDB⽂件城后， Redis启动成功；
AOF/RDB⽂件存在错误时，Redis启动失败并打印错误信息

14.如果突然机器掉电会怎样
取决于AOF⽇志sync属性的配置，如果不要求性能，在每条写指令时都sync⼀下磁盘，就不会丢失数据。但是在⾼性能的要
求下每次都sync是不现实的，⼀般都使⽤定时sync，⽐如1s1次，这个时候最多就会丢失1s的数据。

15.RDB的原理是什么
fork和cow。 fork是指redis通过创建⼦进程来进⾏RDB操作（将数据写入到一个临时的rdb文件，子进程完成写入后，redis会将
新的临时的rdb文件替换掉原来的rdb文件，并删除旧的rdb文件），
cow指的是copy on write，⼦进程创建后，
⽗⼦进程共享数据段，⽗进程继续提供读写服务，写脏的页⾯数据会逐渐和⼦进程分离开来。
fork是操作系统的api，父进程会将新写的数据放在自己的内存中，之后再同步

16.Pipeline有什么好处，为什么要⽤pipeline？
可以将多次IO往返的时间缩减为⼀次，前提是pipeline执⾏的指令之间没有因果相关性。使⽤redisbenchmark进⾏压测
的时候可以发现影响redis的QPS峰值的⼀个重要因素是pipeline批次指令的数⽬

17.Redis的同步机制了解么？
Redis可以使⽤主从同步，从从同步。第⼀次同步时，主节点做⼀次bgsave，并同时将后续修改操作记录到内存buffer，
待完成后将RDB⽂件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期
间修改的操作记录同步到复制节点进⾏重放就完成了同步过程。后续的增量数据通过AOF⽇志同步即可，有点类似数据库的binlog。

18.是否使⽤过Redis集群，集群的⾼可⽤怎么保证，集群的原理是什么？
Redis Sentinal着眼于⾼可⽤，在master宕机时会⾃动将slave提升为master，继续提供服务（高可用）
Redis Cluster着眼于扩展性，在单个redis内存不⾜时，使⽤Cluster进⾏分⽚存储。（可扩展）

============================
redis的雪崩和穿透.pdf
1.Redis雪崩了解么？
电商⾸页以及热点数据都会去做缓存 ，⼀般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有⼀个问题。
某一时间缓存都到期，然后又有很多请求过来，直接穿过缓存打在数据库上，就会打挂数据库
同⼀时间⼤⾯积失效，那⼀瞬间Redis跟没有⼀样，那这个数量级别的请求直接打到数据库⼏乎是灾难性的，你想想如果打挂的
是⼀个⽤户服务的库，那其他依赖他的库所有的接⼝⼏乎都会报错，如果没做熔断等策略基本上就是瞬间挂⼀⽚的节奏

2.那这种情况咋整？你都是怎么去应对的
处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在
同⼀时间⼤⾯积失效
setRedis（Key， value， time + Math.random() * 10000）；
如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题，不过本渣我在⽣产环境中操作
集群的时候，单个服务都是对应的单个Redis分⽚，是为了⽅便数据的管理，但是也同样有了可能会失效这样的弊端，
失效时间随机是个好策略。

或者设置热点数据永远不过期，有更新操作就更新缓存就好了（⽐如运维更新了⾸⻚商品，那你刷下缓
存就完事了，不要设置过期时间），电商⾸⻚的数据也可以⽤这个操作，保险。

3.那你了解缓存穿透和击穿么，可以说说他们跟雪崩的区别么？
缓存穿透：是指缓存和数据库中都没有的数据，⽽⽤户不断发起请求会导致数据库压⼒过⼤，严重会击垮数据库
缓存击穿：是指⼀个Key⾮常热点，在不停的扛着⼤并发，⼤并发集中对这⼀个点进⾏访问，当这个Key在失效的瞬间，
持续的⼤并发就穿破缓存，直接请求数据库，

4.那缓存击穿和缓存穿透怎么解决
缓存穿透：会在接⼝层增加校验，⽐如⽤户鉴权校验，参数做校验，不合法的参数直接代码Return，⽐
如： id 做基础校验， id <=0的直接拦截等
--
不要相信任何调⽤⽅，⽐如你提供了API接⼝出去，你有这⼏个参数，那我觉得作为被调⽤⽅，任何可能的参数情况都应该被
考虑到，做校验，因为你不相信调⽤你的⼈，你不知道他会传什么参数给你。
你这个接⼝是分⻚查询的，但是你没对分⻚参数的⼤⼩做限制，调⽤的⼈万⼀⼀⼝⽓查 Integer.MAX_VALUE ⼀次请求就要你⼏秒，
多⼏个并发你不就挂了么
--
从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体
取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太短会导致正常情况也没法使⽤）
⽹关层Nginx本渣我也记得有配置项，可以让运维⼤⼤对单个IP每秒访问次数超出阈值的IP都拉⿊。
--
布隆过滤器（Bloom Filter） 这个也能很好的防⽌缓存穿透的发⽣，他的原理也很简单就是利⽤⾼效的数据结构
和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。
注意布隆过滤器的优缺点，且只能判断某个数据一定不存在

缓存击穿：设置热点数据永远不过期。或者加上互斥锁就能搞定了

================

避免缓存击穿的利器Bloom Filter.PDF

基本介绍：
实际上是⼀个很长的⼆进制向量和⼀系列随机映射函数，布隆过滤器可以⽤于检索⼀个元素是否不在⼀个集合中。
优点是空间效率和查询时间都远远超过⼀般的算法，缺点是有⼀定的误识别率和删除困难

原理：
当⼀个元素被加⼊集合时，通过K个散列函数将这个元素映射成⼀个位数组中的K个点，把它们置为1。
检索时，我们只要看看这些点是不是都是1就（⼤约）知道集合中有没有它了：如果这些点有任何⼀个0，则被检元素⼀定不在；
如果都是1，则被检元素很可能在（比如A和B的几个哈希函数算出来的值都一样，而库中只有A）。这就是布隆过滤器的基本思想。

Bloom Filter跟单哈希函数Bit-Map不同之处在于：
Bloom Filter使⽤了k个哈希函数，每个字符串跟k个bit对应。从⽽降低了冲突的概率。

Bloom Filter的缺点：存在误判，删除困难。

Bloom Filter 实现：Guava中就提供了⼀种Bloom Filter的实现。

在使⽤bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp，
在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的⼤⼩。

对于⼀个确定的场景，我们预估要存的数据量为n，期望的误判率为fpp，然后需要计算我们需要的Bit数
组的⼤⼩m，以及hash函数的个数k，并选择hash函数（有对应的公式去计算这两个）

